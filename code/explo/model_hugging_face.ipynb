{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d3b09-83a7-4516-bea8-7ce00cc18f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71a81f-e4db-4b1e-80c8-a5d5db75f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d147d-3d91-436d-90b4-d35780f2d745",
   "metadata": {},
   "source": [
    "# Dataset building (skip if already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd82035-1f00-467f-8417-ad8c43615220",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jovyan/hfactory_magic_folders/tooling_for_the_data_scientist/deepfakes_detection/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81959e53-e494-4f9e-9e7f-d4f34302318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/jovyan/project/deepfakes-detection-3-mousketeers/data/train.csv')\n",
    "test_df = pd.read_csv('/home/jovyan/project/deepfakes-detection-3-mousketeers/data/test.csv')\n",
    "\n",
    "train_df['complete_image_id']= train_df.apply(lambda x: x.image_id +'.jpg', axis=1) \n",
    "test_df['complete_image_id']= test_df.apply(lambda x: x.image_id +'.jpg', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf3f11-e7c1-472a-954f-a2d86ec10ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_train_fake = '/home/jovyan/project/deepfakes-detection-3-mousketeers/folder_normalized/train/fake/'\n",
    "destination_train_not_fake = '/home/jovyan/project/deepfakes-detection-3-mousketeers/folder_normalized/train/not_fake/'\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    file_path = path + '/' + file\n",
    "    if file in list(train_df.complete_image_id):\n",
    "        row = train_df[train_df['complete_image_id']==file]\n",
    "        is_deep_fake = int(row['label'])\n",
    "        if is_deep_fake == 1:\n",
    "            shutil.copyfile(file_path, destination_train_fake + file, follow_symlinks = True)\n",
    "        else:\n",
    "            shutil.copyfile(file_path, destination_train_not_fake + file, follow_symlinks = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b93eee-5cf4-45af-8576-217c9cd31c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_test = '/home/jovyan/project/deepfakes-detection-3-mousketeers/folder_normalized/test/'\n",
    "for file in os.listdir(path):\n",
    "    file_path = path + '/' + file\n",
    "    if file in list(test_df.complete_image_id):\n",
    "        shutil.copyfile(file_path, destination_test + file, follow_symlinks = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60671c04-2bb8-49c9-aa13-3e4d65328d79",
   "metadata": {},
   "source": [
    "# Preprocessing / Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4ab4a-6577-414b-89fd-c5306887e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imagefolder\", data_dir=\"/home/jovyan/project/deepfakes-detection-3-mousketeers/folder_normalized/train\", split=\"train\")\n",
    "ds = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2754a1-e9c0-43ee-9850-84be66d34596",
   "metadata": {},
   "source": [
    "### Viewing few examples if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a841e3c-9d1f-4e61-a89c-82b9c1dc0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(ds, seed: int = 1234, examples_per_class: int = 3, size=(350, 350)):\n",
    "\n",
    "    w, h = size\n",
    "    labels = ds['train'].features['label'].names\n",
    "    grid = Image.new('RGB', size=(examples_per_class * w, len(labels) * h))\n",
    "    draw = ImageDraw.Draw(grid)\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf\", 24)\n",
    "\n",
    "    for label_id, label in enumerate(labels):\n",
    "\n",
    "        # Filter the dataset by a single label, shuffle it, and grab a few samples\n",
    "        ds_slice = ds['train'].filter(lambda ex: ex['label'] == label_id).shuffle(seed).select(range(examples_per_class))\n",
    "\n",
    "        # Plot this label's examples along a row\n",
    "        for i, example in enumerate(ds_slice):\n",
    "            image = example['image']\n",
    "            idx = examples_per_class * label_id + i\n",
    "            box = (idx % examples_per_class * w, idx // examples_per_class * h)\n",
    "            grid.paste(image.resize(size), box=box)\n",
    "            draw.text(box, label, (255, 255, 255), font=font)\n",
    "\n",
    "    return grid\n",
    "\n",
    "show_examples(ds, seed=random.randint(0, 1337), examples_per_class=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2800e99f-3de4-4ba7-a824-2458904411db",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fe523-27f5-43ef-85d3-482125dafacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ds[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa726194-b192-411f-aec7-d54f6d230811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095e8b3-efa0-48c1-9487-a25acd9d00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "_transforms = Compose([RandomResizedCrop(feature_extractor.size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ea7f3-855e-46d1-874b-d5154b291eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f66bfa-6369-4ca3-9998-31d7d0cf7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b24fdc-c00a-4da0-8e59-7946742ecf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265e29a-9edf-4f04-92d3-d0d3afbc435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373aaf0a-feef-4be4-8b0e-762bb35b305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=4,\n",
    "    fp16=False,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
